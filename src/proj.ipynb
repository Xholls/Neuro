{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCfLtbcTmyaUYsRFMcVqlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xholls/Neuro/blob/main/src/proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Xholls/Neuro.git"
      ],
      "metadata": {
        "id": "VQW2sMzog1cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc7BPVm1wEd4",
        "outputId": "fc8ee259-1e88-4b0d-c130-152a48110a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n",
            "GPU is OFF\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from skimage import measure\n",
        "from skimage.io import imread, imsave, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.filters import gaussian\n",
        "from skimage.morphology import dilation, disk\n",
        "from skimage.draw import polygon, polygon_perimeter\n",
        "\n",
        "print(f'Tensorflow version {tf.__version__}')\n",
        "print(f'GPU is {\"ON\" if tf.config.list_physical_devices(\"GPU\") else \"OFF\" }')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = 8\n",
        "\n",
        "COLORS = ['black', 'red', 'lime',\n",
        "          'blue', 'orange', 'pink',\n",
        "          'cyan', 'magenta']\n",
        "\n",
        "SAMPLE_SIZE = (256, 256)\n",
        "\n",
        "OUTPUT_SIZE = (1080, 1920)"
      ],
      "metadata": {
        "id": "lbejDT5ywRSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(image, mask):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image)\n",
        "    image = tf.image.resize(image, OUTPUT_SIZE)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = image / 255.0\n",
        "\n",
        "    mask = tf.io.read_file(mask)\n",
        "    mask = tf.io.decode_png(mask)\n",
        "    mask = tf.image.rgb_to_grayscale(mask)\n",
        "    mask = tf.image.resize(mask, OUTPUT_SIZE)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "\n",
        "    masks = []\n",
        "\n",
        "    for i in range(CLASSES):\n",
        "        masks.append(tf.where(tf.equal(mask, float(i)), 1.0, 0.0))\n",
        "\n",
        "    masks = tf.stack(masks, axis=2)\n",
        "    masks = tf.reshape(masks, OUTPUT_SIZE + (CLASSES,))\n",
        "\n",
        "    return image, masks\n",
        "\n",
        "def augmentate_images(image, masks):\n",
        "    random_crop = tf.random.uniform((), 0.3, 1)\n",
        "    image = tf.image.central_crop(image, random_crop)\n",
        "    masks = tf.image.central_crop(masks, random_crop)\n",
        "\n",
        "    random_flip = tf.random.uniform((), 0, 1)\n",
        "    if random_flip >= 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        masks = tf.image.flip_left_right(masks)\n",
        "\n",
        "    image = tf.image.resize(image, SAMPLE_SIZE)\n",
        "    masks = tf.image.resize(masks, SAMPLE_SIZE)\n",
        "\n",
        "    return image, masks"
      ],
      "metadata": {
        "id": "d0hTeLtexwKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = sorted(glob.glob('SemanticSegmentationLesson/dataset/images/*.jpg'))\n",
        "masks = sorted(glob.glob('SemanticSegmentationLesson/dataset/masks/*.png'))\n",
        "\n",
        "images_dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "masks_dataset = tf.data.Dataset.from_tensor_slices(masks)\n",
        "\n",
        "dataset = tf.data.Dataset.zip((images_dataset, masks_dataset))\n",
        "\n",
        "dataset = dataset.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.repeat(60)\n",
        "dataset = dataset.map(augmentate_images, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "OPcjQjj94Ln5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_and_masks = list(dataset.take(5))\n",
        "\n",
        "fig, ax = plt.subplots(nrows = 2, ncols = 5, figsize=(15, 5), dpi=125)\n",
        "\n",
        "for i, (image, masks) in enumerate(images_and_masks):\n",
        "    ax[0, i].set_title('Image')\n",
        "    ax[0, i].set_axis_off()\n",
        "    ax[0, i].imshow(image)\n",
        "\n",
        "    ax[1, i].set_title('Mask')\n",
        "    ax[1, i].set_axis_off()\n",
        "    ax[1, i].imshow(image/1.5)\n",
        "\n",
        "    for channel in range(CLASSES):\n",
        "        contours = measure.find_contours(np.array(masks[:,:,channel]))\n",
        "        for contour in contours:\n",
        "            ax[1, i].plot(contour[:, 1], contour[:, 0], linewidth=1, color=COLORS[channel])\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "8G7f-md34O1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(2000).cache()\n",
        "test_dataset = dataset.skip(2000).take(100).cache()\n",
        "\n",
        "train_dataset = train_dataset.batch(16)\n",
        "test_dataset = test_dataset.batch(16)"
      ],
      "metadata": {
        "id": "8V4KvxHB4TLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_layer():\n",
        "    return tf.keras.layers.Input(shape=SAMPLE_SIZE + (3,))\n",
        "\n",
        "def downsample_block(filters, size, batch_norm=True):\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if batch_norm:\n",
        "        result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "def upsample_block(filters, size, dropout=False):\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(\n",
        "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                        kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    if dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "    return result\n",
        "\n",
        "def output_layer(size):\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "    return tf.keras.layers.Conv2DTranspose(CLASSES, size, strides=2, padding='same',\n",
        "                                           kernel_initializer=initializer, activation='sigmoid')"
      ],
      "metadata": {
        "id": "SoosNdAG4TRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = input_layer()\n",
        "\n",
        "downsample_stack = [\n",
        "    downsample_block(64, 4, batch_norm=False),\n",
        "    downsample_block(128, 4),\n",
        "    downsample_block(256, 4),\n",
        "    downsample_block(512, 4),\n",
        "    downsample_block(512, 4),\n",
        "    downsample_block(512, 4),\n",
        "    downsample_block(512, 4),\n",
        "]\n",
        "\n",
        "upsample_stack = [\n",
        "    upsample_block(512, 4, dropout=True),\n",
        "    upsample_block(512, 4, dropout=True),\n",
        "    upsample_block(512, 4, dropout=True),\n",
        "    upsample_block(256, 4),\n",
        "    upsample_block(128, 4),\n",
        "    upsample_block(64, 4)\n",
        "]\n",
        "\n",
        "out_layer = output_layer(4)\n",
        "\n",
        "# Реализуем skip connections\n",
        "x = inp_layer\n",
        "\n",
        "downsample_skips = []\n",
        "\n",
        "for block in downsample_stack:\n",
        "    x = block(x)\n",
        "    downsample_skips.append(x)\n",
        "\n",
        "downsample_skips = reversed(downsample_skips[:-1])\n",
        "\n",
        "for up_block, down_block in zip(upsample_stack, downsample_skips):\n",
        "    x = up_block(x)\n",
        "    x = tf.keras.layers.Concatenate()([x, down_block])\n",
        "\n",
        "out_layer = out_layer(x)\n",
        "\n",
        "unet_like = tf.keras.Model(inputs=inp_layer, outputs=out_layer)\n",
        "\n",
        "tf.keras.utils.plot_model(unet_like, show_shapes=True, dpi=72)"
      ],
      "metadata": {
        "id": "qLAF_nw24XbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_mc_metric(a, b):\n",
        "    a = tf.unstack(a, axis=3)\n",
        "    b = tf.unstack(b, axis=3)\n",
        "\n",
        "    dice_summ = 0\n",
        "\n",
        "    for i, (aa, bb) in enumerate(zip(a, b)):\n",
        "        numenator = 2 * tf.math.reduce_sum(aa * bb) + 1\n",
        "        denomerator = tf.math.reduce_sum(aa + bb) + 1\n",
        "        dice_summ += numenator / denomerator\n",
        "\n",
        "    avg_dice = dice_summ / CLASSES\n",
        "\n",
        "    return avg_dice\n",
        "\n",
        "def dice_mc_loss(a, b):\n",
        "    return 1 - dice_mc_metric(a, b)\n",
        "\n",
        "def dice_bce_mc_loss(a, b):\n",
        "    return 0.3 * dice_mc_loss(a, b) + tf.keras.losses.binary_crossentropy(a, b)"
      ],
      "metadata": {
        "id": "JqD6ylRA4Zhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_like.compile(optimizer='adam', loss=[dice_bce_mc_loss], metrics=[dice_mc_metric])"
      ],
      "metadata": {
        "id": "saiZKtQ74dGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dice = unet_like.fit(train_dataset, validation_data=test_dataset, epochs=25, initial_epoch=0)\n",
        "\n",
        "unet_like.save_weights('SemanticSegmentationLesson/networks/unet_like')"
      ],
      "metadata": {
        "id": "vfsYiDHh4e7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_like.load_weights('SemanticSegmentationLesson/networks/unet_like')"
      ],
      "metadata": {
        "id": "Y6HrjlHA4gX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_colors = [\n",
        "    (0,   0,   0),\n",
        "    (255, 0,   0),\n",
        "    (0,   255, 0),\n",
        "    (0,   0,   255),\n",
        "    (255, 165, 0),\n",
        "    (255, 192, 203),\n",
        "    (0,   255, 255),\n",
        "    (255, 0,   255)\n",
        "]\n",
        "\n",
        "frames = sorted(glob.glob('SemanticSegmentationLesson/videos/original_video/*.jpg'))\n",
        "\n",
        "for filename in frames:\n",
        "    frame = imread(filename)\n",
        "    sample = resize(frame, SAMPLE_SIZE)\n",
        "\n",
        "    predict = unet_like.predict(sample.reshape((1,) +  SAMPLE_SIZE + (3,)))\n",
        "    predict = predict.reshape(SAMPLE_SIZE + (CLASSES,))\n",
        "\n",
        "    scale = frame.shape[0] / SAMPLE_SIZE[0], frame.shape[1] / SAMPLE_SIZE[1]\n",
        "\n",
        "    frame = (frame / 1.5).astype(np.uint8)\n",
        "\n",
        "    for channel in range(1, CLASSES):\n",
        "        contour_overlay = np.zeros((frame.shape[0], frame.shape[1]))\n",
        "        contours = measure.find_contours(np.array(predict[:,:,channel]))\n",
        "\n",
        "        try:\n",
        "            for contour in contours:\n",
        "                rr, cc = polygon_perimeter(contour[:, 0] * scale[0],\n",
        "                                           contour[:, 1] * scale[1],\n",
        "                                           shape=contour_overlay.shape)\n",
        "\n",
        "                contour_overlay[rr, cc] = 1\n",
        "\n",
        "            contour_overlay = dilation(contour_overlay, disk(1))\n",
        "            frame[contour_overlay == 1] = rgb_colors[channel]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    imsave(f'SemanticSegmentationLesson/videos/processed/{os.path.basename(filename)}', frame)"
      ],
      "metadata": {
        "id": "cpsbXCQI4i8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}